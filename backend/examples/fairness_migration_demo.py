"""
Fairness-Bias Integration Script

This script demonstrates how to migrate from the standalone fairness-bias
module to the integrated AI governance framework approach.
"""

import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.preprocessing import LabelEncoder, StandardScaler
from sklearn.impute import SimpleImputer
import warnings
warnings.filterwarnings('ignore')

# Import the newly integrated fairness module
from ai_governance_framework.core.fairness import (
    FairnessOptimizer,
    FairnessConfig,
    FairnessVisualizer
)


def migrate_existing_analysis():
    """
    Migrate existing analysis from standalone fairness-bias to integrated framework.
    """
    print("ðŸ”„ Migrating Fairness-Bias Analysis to AI Governance Framework")
    print("=" * 65)
    
    # Check if original data file exists
    try:
        # Try to load the original data
        data_path = "/Users/jullas/ghci/fairness-bias/data.csv"
        df = pd.read_csv(data_path)
        print(f"âœ… Loaded original dataset: {df.shape}")
        
        # Preprocess using enhanced methods
        X_processed, y, sensitive_features = enhanced_preprocessing(df)
        
    except FileNotFoundError:
        print("ðŸ“Š Original data not found. Creating synthetic data for demo...")
        X_processed, y, sensitive_features = create_synthetic_loan_data()
    
    # Split data
    X_train, X_test, y_train, y_test = train_test_split(
        X_processed, y, test_size=0.3, random_state=42, stratify=y
    )
    
    print(f"Training set: {X_train.shape}")
    print(f"Test set: {X_test.shape}")
    print(f"Sensitive features: {sensitive_features}")
    
    # Compare old vs new approach
    print("\nðŸ†š Comparing Approaches:")
    print("-" * 25)
    
    # OLD APPROACH (standalone fairness-bias)
    print("ðŸŸ¡ OLD: Standalone fairness-bias approach")
    results_old = run_old_style_analysis(X_train, X_test, y_train, y_test, sensitive_features)
    
    # NEW APPROACH (integrated AI governance)
    print("ðŸŸ¢ NEW: Integrated AI governance approach")
    results_new = run_new_integrated_analysis(X_train, X_test, y_train, y_test, sensitive_features)
    
    # Compare results
    print("\nðŸ“Š Results Comparison:")
    print("-" * 20)
    compare_results(results_old, results_new)
    
    # Show enhanced features
    demonstrate_enhanced_features(X_test, y_test, sensitive_features)
    
    print("\nâœ… Migration Complete!")
    return results_old, results_new


def enhanced_preprocessing(df):
    """Enhanced preprocessing with better handling of missing values and scaling."""
    print("ðŸ”§ Enhanced preprocessing...")
    
    # Assume the dataset has loan approval prediction structure
    if 'Loan_Status' in df.columns:
        y = (df['Loan_Status'] == 'Y').astype(int)
        X = df.drop('Loan_Status', axis=1)
    else:
        # Handle different target column names
        target_cols = ['target', 'loan_approved', 'approved', 'outcome']
        target_col = None
        for col in target_cols:
            if col in df.columns:
                target_col = col
                break
        
        if target_col:
            y = df[target_col].astype(int)
            X = df.drop(target_col, axis=1)
        else:
            raise ValueError("No recognized target column found")
    
    # Identify sensitive features
    sensitive_candidates = ['gender', 'Gender', 'sex', 'race', 'ethnicity']
    sensitive_features = [col for col in X.columns if any(s.lower() in col.lower() for s in sensitive_candidates)]
    
    if not sensitive_features:
        # Create synthetic sensitive feature
        print("âš ï¸ No sensitive features found. Creating synthetic gender feature.")
        X['gender'] = np.random.choice(['Male', 'Female'], len(X))
        sensitive_features = ['gender']
    
    # Enhanced preprocessing
    numerical_cols = X.select_dtypes(include=[np.number]).columns.tolist()
    categorical_cols = X.select_dtypes(include=['object']).columns.tolist()
    
    # Handle missing values
    if numerical_cols:
        imputer_num = SimpleImputer(strategy='median')
        X[numerical_cols] = imputer_num.fit_transform(X[numerical_cols])
    
    if categorical_cols:
        imputer_cat = SimpleImputer(strategy='most_frequent')
        X[categorical_cols] = imputer_cat.fit_transform(X[categorical_cols])
    
    # Encode categorical variables
    le_dict = {}
    for col in categorical_cols:
        le = LabelEncoder()
        X[f'{col}_encoded'] = le.fit_transform(X[col])
        le_dict[col] = le
        
        # Update sensitive features list if needed
        if col in sensitive_features:
            sensitive_features[sensitive_features.index(col)] = f'{col}_encoded'
    
    # Select features for modeling
    feature_cols = numerical_cols + [f'{col}_encoded' for col in categorical_cols]
    X_processed = X[feature_cols]
    
    # Scale numerical features
    if numerical_cols:
        scaler = StandardScaler()
        X_processed[numerical_cols] = scaler.fit_transform(X_processed[numerical_cols])
    
    print(f"âœ… Preprocessing complete. Features: {X_processed.shape[1]}")
    
    return X_processed, y, sensitive_features


def create_synthetic_loan_data():
    """Create synthetic loan data for demonstration."""
    print("ðŸŽ² Creating synthetic loan dataset...")
    
    np.random.seed(42)
    n_samples = 1000
    
    # Create features
    df = pd.DataFrame({
        'age': np.random.normal(35, 12, n_samples),
        'income': np.random.normal(60000, 25000, n_samples),
        'credit_score': np.random.normal(650, 100, n_samples),
        'employment_years': np.random.exponential(5, n_samples),
        'gender': np.random.choice(['Male', 'Female'], n_samples),
        'education': np.random.choice(['High School', 'Bachelor', 'Master', 'PhD'], n_samples),
        'marital_status': np.random.choice(['Single', 'Married', 'Divorced'], n_samples)
    })
    
    # Create biased target
    # Higher approval for males and higher income
    gender_bias = np.where(df['gender'] == 'Male', 0.15, 0)
    income_factor = (df['income'] - df['income'].mean()) / df['income'].std() * 0.1
    credit_factor = (df['credit_score'] - 600) / 100 * 0.2
    
    approval_prob = 0.4 + gender_bias + income_factor + credit_factor
    approval_prob = np.clip(approval_prob, 0, 1)
    
    df['loan_approved'] = np.random.binomial(1, approval_prob, n_samples)
    
    # Process like real data
    X_processed, y, sensitive_features = enhanced_preprocessing(df)
    
    return X_processed, y, sensitive_features


def run_old_style_analysis(X_train, X_test, y_train, y_test, sensitive_features):
    """Simulate old standalone fairness-bias approach."""
    print("  Running basic fairness analysis...")
    
    # Basic model training (simulating old approach)
    model = RandomForestClassifier(n_estimators=50, random_state=42)
    model.fit(X_train, y_train)
    
    # Basic evaluation
    y_pred = model.predict(X_test)
    from sklearn.metrics import accuracy_score, classification_report
    
    accuracy = accuracy_score(y_test, y_pred)
    print(f"  Accuracy: {accuracy:.3f}")
    
    # Basic fairness check (simplified)
    if sensitive_features and len(sensitive_features) > 0:
        sensitive_col = sensitive_features[0]
        if sensitive_col in X_test.columns:
            # Group analysis
            unique_groups = X_test[sensitive_col].unique()
            group_accuracies = {}
            
            for group in unique_groups:
                group_mask = X_test[sensitive_col] == group
                if group_mask.sum() > 0:
                    group_acc = accuracy_score(y_test[group_mask], y_pred[group_mask])
                    group_accuracies[group] = group_acc
            
            disparity = max(group_accuracies.values()) - min(group_accuracies.values()) if group_accuracies else 0
            print(f"  Accuracy Disparity: {disparity:.3f}")
        else:
            disparity = 0
    else:
        disparity = 0
    
    return {
        'accuracy': accuracy,
        'disparity': disparity,
        'approach': 'standalone'
    }


def run_new_integrated_analysis(X_train, X_test, y_train, y_test, sensitive_features):
    """Run new integrated AI governance approach."""
    print("  Running integrated fairness analysis...")
    
    # Advanced configuration
    config = FairnessConfig(
        mitigation='reduction',
        objective='equalized_odds',
        statistical_testing=True,
        confidence_intervals=True
    )
    
    # Create optimizer
    optimizer = FairnessOptimizer(
        base_estimator=RandomForestClassifier(n_estimators=50, random_state=42),
        sensitive_feature_names=sensitive_features,
        config=config
    )
    
    # Fit and evaluate
    try:
        optimizer.fit(X_train, y_train)
        results = optimizer.evaluate(X_test, y_test)
        
        accuracy = results['overall']['accuracy']
        disparity = results.get('accuracy_disparity', 0)
        if disparity == 0 and 'fairness' in results:
            disparity = results['fairness']['disparities'].get('accuracy_disparity', 0)
        
        print(f"  Accuracy: {accuracy:.3f}")
        print(f"  Accuracy Disparity: {disparity:.3f}")
        
        # Statistical significance
        if 'statistical_tests' in results:
            stat_tests = results['statistical_tests']
            if 'selection_rate_test' in stat_tests:
                p_val = stat_tests['selection_rate_test'].get('p_value', 1.0)
                significance = "Significant" if p_val < 0.05 else "Not Significant"
                print(f"  Statistical Test: {significance} (p={p_val:.4f})")
        
        return {
            'accuracy': accuracy,
            'disparity': disparity,
            'approach': 'integrated',
            'full_results': results
        }
        
    except Exception as e:
        print(f"  Error in integrated analysis: {e}")
        return {
            'accuracy': 0,
            'disparity': 0,
            'approach': 'integrated',
            'error': str(e)
        }


def compare_results(old_results, new_results):
    """Compare old vs new approach results."""
    print("\nðŸ“ˆ Performance Comparison:")
    print(f"OLD Approach - Accuracy: {old_results['accuracy']:.3f}, Disparity: {old_results['disparity']:.3f}")
    print(f"NEW Approach - Accuracy: {new_results['accuracy']:.3f}, Disparity: {new_results['disparity']:.3f}")
    
    # Improvements
    acc_improvement = new_results['accuracy'] - old_results['accuracy']
    disp_improvement = old_results['disparity'] - new_results['disparity']  # Lower is better
    
    print(f"\nðŸ“Š Improvements:")
    print(f"Accuracy change: {acc_improvement:+.3f}")
    print(f"Fairness improvement: {disp_improvement:+.3f} (positive = more fair)")
    
    if 'full_results' in new_results:
        print("\nðŸ”¬ Enhanced Analysis Available:")
        full_results = new_results['full_results']
        
        if 'statistical_tests' in full_results:
            print("  âœ… Statistical significance testing")
        if 'confidence_intervals' in full_results:
            print("  âœ… Confidence intervals")
        if 'fairness' in full_results and 'by_group' in full_results['fairness']:
            print("  âœ… Detailed group-wise analysis")


def demonstrate_enhanced_features(X_test, y_test, sensitive_features):
    """Demonstrate enhanced features of the integrated framework."""
    print("\nðŸš€ Enhanced Features Demo:")
    print("-" * 25)
    
    # Advanced configuration options
    configs = {
        'Ensemble Method': FairnessConfig(
            mitigation='ensemble',
            ensemble_config={
                'type': 'voting',
                'n_estimators': 3
            }
        ),
        'Multi-objective': FairnessConfig(
            mitigation='multi_objective',
            multi_objective_config={
                'objectives': ['accuracy', 'fairness'],
                'weights': [0.7, 0.3]
            }
        ),
        'Full Analysis': FairnessConfig(
            mitigation='reduction',
            statistical_testing=True,
            confidence_intervals=True,
            robustness_analysis=False  # Set to False for demo speed
        )
    }
    
    print("Available advanced configurations:")
    for name, config in configs.items():
        print(f"  âœ“ {name}: {config.mitigation}")
    
    # Visualization capabilities
    print("\nðŸ“Š Visualization Capabilities:")
    visualizer = FairnessVisualizer()
    print("  âœ“ Fairness-Accuracy Trade-off plots")
    print("  âœ“ Group performance comparisons")
    print("  âœ“ Bias detection summaries")
    print("  âœ“ Comprehensive fairness dashboards")
    print("  âœ“ Confidence interval plots")
    
    # Integration points
    print("\nðŸ”— Framework Integration:")
    print("  âœ“ Compliance policy checking")
    print("  âœ“ Audit trail logging")
    print("  âœ“ Explainability integration")
    print("  âœ“ Model governance workflows")


def create_migration_summary():
    """Create a summary of the migration benefits."""
    print("\nðŸ“‹ Migration Summary")
    print("=" * 20)
    
    benefits = [
        "ðŸŽ¯ Advanced fairness optimization algorithms",
        "ðŸ“Š Comprehensive statistical testing",
        "ðŸ”¬ Bootstrap confidence intervals",
        "ðŸŽ¨ Rich visualization capabilities", 
        "ðŸ›ï¸ Integrated compliance checking",
        "ðŸ“ Automated audit logging",
        "ðŸ”— Seamless explainability integration",
        "âš™ï¸ Configurable optimization strategies",
        "ðŸ§ª Robustness analysis tools",
        "ðŸ“ˆ Enhanced reporting capabilities"
    ]
    
    print("Benefits of integrated approach:")
    for benefit in benefits:
        print(f"  {benefit}")
    
    print("\nðŸŽ‰ The fairness-bias module has been successfully integrated!")
    print("ðŸ”¥ You now have access to production-ready fairness optimization!")


if __name__ == "__main__":
    # Run migration demo
    old_results, new_results = migrate_existing_analysis()
    
    # Create summary
    create_migration_summary()
    
    print("\n" + "=" * 60)
    print("ðŸŽ¯ Integration Complete - Ready for Production Use!")
    print("=" * 60)